from torchtyping import TensorType

from common.modeling import MixIn
from common.utils import (
    freeze_module, unfreeze_module,
    sample_lognorm_timesteps,
    rectflow_lerp, rectflow_sampling
)

from .feature_discriminator import DiscriminatorHead, MixingDiscriminatorHead

from torch import nn
import torch.nn.functional as F
from copy import deepcopy

class LADD(MixIn):
    """
    Latent Adversarial Diffusion Distillation module

    :param student: Student denoiser model
    :param teacher: Teacher denoiser model. Should output hidden states for adversarial heads to be trained on.

    :param vit_config: vit_config for the teacher (needed to make disc layers)
    :param disc_config: Config for the discriminator transformer layers (ViTConfig)
    :param vae: Optional module for inference/sampling only
    :param adv_weight: Weight of adversarial loss when training student
    :param teacher_inference_steps: Number of inference steps for teacher
    :param student_inference_steps: Number of inference steps for student
    :param sampling_fn: Some function that can take a student or teacher model, a number of steps, text_features, and generate a sample
    """
    def __init__(
        self,
        student, teacher,
        vit_config, disc_config,
        vae = None,
        adv_weight = 0.1,
        teacher_inference_steps = 50, student_inference_steps = 25
    ):
        super().__init__()

        freeze_module(teacher)
        if vae is not None:
            freeze_module(vae)

        self.student = student
        self.teacher = teacher
        self.vae = vae
        self.adv_weight = adv_weight

        self.disc = nn.ModuleList([
            DiscriminatorHead(vit_config.hidden_size, disc_config)
        ] * vit_config.n_layers)

        self.train_disc = False
        self.focus_main()

        self.t_steps = teacher_inference_steps
        self.s_steps = student_inference_steps
        self.config = vit_config
    
    def focus_main(self):
        freeze_module(self.disc)
        unfreeze_module(self.student)

    def focus_disc(self):
        freeze_module(self.student)
        unfreeze_module(self.disc)
    
    @torch.no_grad()
    def teacher_sample(self, text_features):
        """
        Sample a generation using teacher
        """
        return rectflow_sampling(self.teacher, self.config.input_shape, text_features, self.t_steps)

    def teacher_discriminate(self, real, fake, text_features, timesteps):
        _, h_real = self.teacher(real, text_features, timesteps, output_hidden_states = True)
        _, h_fake = self.teacher(fake, text_features, timesteps, output_hidden_states = True)

        loss = 0.
        adv_loss = 0.
        for (disc, h_r_i, h_f_i) in zip(self.disc, h_real, h_fake):
            loss_i, adv_loss_i = disc(h_r_i, h_f_i)
            loss += loss_i
            adv_loss += adv_loss_i

        return loss, adv_loss

    
    def forward(self, text_features : TensorType["b", "n", "d"]):
        """
        Forward given text features. All actual latents are generated by the teacher.
        """
        # Sample generations for the batch
        samples = teacher_sample(text_features).detach()
        noise = torch.randn_like(samples)

        # Different timesteps for distillation and adversarial term
        timesteps_distill = sample_lognorm_timesteps(text_features)
        timesteps_adv = sample_lognorm_timesteps(text_features)

        # Perturb the samples with noise then use student output to get prediction of the original image
        perturbed = rectflow_lerp(samples, noise, timesteps_distill).detach()
        student_v_pred = self.student(perturbed, text_features, timesteps_distill) # (x - z)
        student_x_pred = noise + student_v_pred

        # For adversarial part, renoise the student generation
        perturbed_adv_fake = rectflow_lerp(student_x_pred, noise, timesteps_distill)
        perturbed_adv_fake = rectflow_lerp(samples, noise, timesteps_distill)

        if self.train_disc:
            loss, _ = self.teacher_discriminate(perturbed_adv_real, perturbed_adv_fake, text_features, timesteps)
            return loss
        else:
            # Distillation loss is to reconstruct the generated image
            dist_loss = F.mse_loss(student_x_pred, samples)

            # Adv loss to fool discriminator
            _, adv_loss = self.teacher_discriminate(perturbed_adv_real, perturbed_adv_fake, text_features, timesteps)
            return dist_loss + self.adv_weight * adv_loss


if __name__ == "__main__":
    from common.configs import ViTConfig

    model_config = ViTConfig(
        n_layers = 18,
        n_heads = 16,
        hidden_size = 1874,
        input_shape = (4, 64, 64),
        patching = (8, 8),
        flash = False
    )

    disc_config = ViTConfig(
        n_layers = 4,
        n_heads = 4,
        hidden_size = 384
    )